[0;35mCanvasBot Robust Orchestrator[0m
[0;35m============================[0m

Usage: ./scripts/orchestrator.sh [COMMAND]

COMMANDS:
  start     - Start all CanvasBot services with intelligent recovery
  stop      - Gracefully stop all services
  restart   - Restart all services
  status    - Show detailed system status
  validate  - Validate environment and configuration
  logs      - Show orchestrator logs
  help      - Show this help message

FEATURES:
  ✅ Intelligent container lifecycle management
  ✅ Progressive health checking with adaptive timeouts
  ✅ Automatic service recovery and fallback strategies
  ✅ Comprehensive environment validation
  ✅ Graceful degradation for partial failures
  ✅ Detailed logging and monitoring

EXAMPLES:
  ./scripts/orchestrator.sh start     # Start with full validation and recovery
  ./scripts/orchestrator.sh status    # Check current system health
  ./scripts/orchestrator.sh logs      # Monitor orchestrator activity
[0;36m[2025-08-21 22:03:22] [INFO] 📊 Checking system status...[0m
[0;36m[2025-08-21 22:03:22] [INFO] 📊 Generating system status report...[0m

[0;34m╔══════════════════════════════════════════════╗[0m
[0;34m║                System Status                 ║[0m
[0;34m╚══════════════════════════════════════════════╝[0m

[0;36mOperation Mode:[0m FULL
[0;36mOrchestrator State:[0m INITIALIZING
[0;36mRuntime:[0m 0 seconds

[1;33mService Status:[0m

[1;33mService URLs:[0m
  🤖 CanvasBot API: http://localhost:3001
  🌐 Open WebUI: http://localhost:8081
  ⚡ vLLM API: http://localhost:8000
  🧠 Ollama API: http://localhost:11435

[0;31m⚠️ Critical Issues Detected:[0m
  ❌ Essential service ollama is not healthy
  ❌ Essential service canvasbot is not healthy
  ❌ Canvas access token not configured

[1;33m💡 Troubleshooting Steps:[0m
  1. Check logs: [0;36mtail -f /home/bencan/projects/canvasCheckerBot/logs/orchestrator.log[0m
  2. Restart services: [0;36m./scripts/orchestrator.sh restart[0m
  3. Check configuration: [0;36m./scripts/orchestrator.sh validate[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🔍 Running environment validation...[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🔍 Starting comprehensive environment validation...[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Canvas credentials found[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Docker is available and running[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Docker Compose available[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🎮 Checking GPU availability...[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Found 3 GPU(s) available[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🔗 Multi-GPU detected, checking NCCL compatibility...[0m
[1;33m[2025-08-21 22:03:35] [WARN] ⚠️ Multi-GPU vLLM configured - will attempt with fallback to single GPU[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🔌 Checking port availability...[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ All required ports are available[0m
[0;36m[2025-08-21 22:03:35] [INFO] 🤖 Validating model configuration...[0m
[0;36m[2025-08-21 22:03:35] [INFO] 📋 vLLM Model: Qwen/Qwen2.5-32B-Instruct-AWQ[0m
[0;36m[2025-08-21 22:03:35] [INFO] 📋 Embedding Model: nomic-embed-text[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Model configuration validated[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Environment validation passed[0m
[0;32m[2025-08-21 22:03:35] [SUCCESS] ✅ Environment validation passed[0m
[0;35m
╔══════════════════════════════════════════════════════════════╗
║                    CanvasBot Orchestrator                    ║
║              Robust Startup & Recovery System               ║
╚══════════════════════════════════════════════════════════════╝
[0m
[0;36m[2025-08-21 22:04:28] [INFO] 🚀 Starting CanvasBot system with robust orchestration...[0m
[0;36m[2025-08-21 22:04:28] [INFO] 🔍 Starting comprehensive environment validation...[0m
[0;32m[2025-08-21 22:04:28] [SUCCESS] ✅ Canvas credentials found[0m
[0;32m[2025-08-21 22:04:28] [SUCCESS] ✅ Docker is available and running[0m
[0;32m[2025-08-21 22:04:28] [SUCCESS] ✅ Docker Compose available[0m
[0;36m[2025-08-21 22:04:28] [INFO] 🎮 Checking GPU availability...[0m
[0;32m[2025-08-21 22:04:29] [SUCCESS] ✅ Found 3 GPU(s) available[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🔗 Multi-GPU detected, checking NCCL compatibility...[0m
[1;33m[2025-08-21 22:04:29] [WARN] ⚠️ Multi-GPU vLLM configured - will attempt with fallback to single GPU[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🔌 Checking port availability...[0m
[0;32m[2025-08-21 22:04:29] [SUCCESS] ✅ All required ports are available[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🤖 Validating model configuration...[0m
[0;36m[2025-08-21 22:04:29] [INFO] 📋 vLLM Model: Qwen/Qwen2.5-32B-Instruct-AWQ[0m
[0;36m[2025-08-21 22:04:29] [INFO] 📋 Embedding Model: nomic-embed-text[0m
[0;32m[2025-08-21 22:04:29] [SUCCESS] ✅ Model configuration validated[0m
[0;32m[2025-08-21 22:04:29] [SUCCESS] ✅ Environment validation passed[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🎼 Starting service orchestration...[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🚀 Processing service: ollama[0m
[0;36m[2025-08-21 22:04:29] [INFO] 📊 ollama current state: MISSING[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🆕 ollama container missing, creating new[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🆕 Creating new ollama container...[0m
[0;31m[2025-08-21 22:04:29] [ERROR] ❌ Failed to create ollama container[0m
[0;31m[2025-08-21 22:04:29] [ERROR] 💥 Service failure detected for: ollama[0m
[0;31m[2025-08-21 22:04:29] [ERROR] 🚨 Essential service ollama failed - attempting recovery[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🔄 Attempting recovery for ollama (retry 1/3)[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🗑️ Removing stale ollama container...[0m
[0;36m[2025-08-21 22:04:29] [INFO] 🆕 Creating new ollama container...[0m
[0;31m[2025-08-21 22:04:30] [ERROR] ❌ Failed to create ollama container[0m
[0;31m[2025-08-21 22:04:30] [ERROR] 💥 Service failure detected for: ollama[0m
[0;31m[2025-08-21 22:04:30] [ERROR] 🚨 Essential service ollama failed - attempting recovery[0m
[0;36m[2025-08-21 22:04:30] [INFO] 🔄 Attempting recovery for ollama (retry 2/3)[0m
[0;36m[2025-08-21 22:04:30] [INFO] 🗑️ Removing stale ollama container...[0m
[0;36m[2025-08-21 22:04:30] [INFO] 🆕 Creating new ollama container...[0m
[0;31m[2025-08-21 22:04:31] [ERROR] ❌ Failed to create ollama container[0m
[0;31m[2025-08-21 22:04:31] [ERROR] 💥 Service failure detected for: ollama[0m
[0;31m[2025-08-21 22:04:31] [ERROR] 🚨 Essential service ollama failed - attempting recovery[0m
[0;36m[2025-08-21 22:04:31] [INFO] 🔄 Attempting recovery for ollama (retry 3/3)[0m
[0;36m[2025-08-21 22:04:31] [INFO] 🗑️ Removing stale ollama container...[0m
[0;36m[2025-08-21 22:04:31] [INFO] 🆕 Creating new ollama container...[0m
[0;31m[2025-08-21 22:04:31] [ERROR] ❌ Failed to create ollama container[0m
[0;31m[2025-08-21 22:04:31] [ERROR] 💥 Service failure detected for: ollama[0m
[0;31m[2025-08-21 22:04:31] [ERROR] 🚨 Essential service ollama failed - attempting recovery[0m
[0;31m[2025-08-21 22:04:31] [ERROR] 💀 Max retries exceeded for ollama - entering degraded mode[0m
[0;36m[2025-08-21 22:04:31] [INFO] ⏳ Waiting for ollama to be ready...[0m
[0;36m[2025-08-21 22:04:41] [INFO] ⏳ Still waiting for ollama... (10s/300s)[0m
[0;36m[2025-08-21 22:04:51] [INFO] ⏳ Still waiting for ollama... (20s/300s)[0m
[0;36m[2025-08-21 22:05:01] [INFO] ⏳ Still waiting for ollama... (30s/300s)[0m
[0;36m[2025-08-21 22:05:11] [INFO] ⏳ Still waiting for ollama... (40s/300s)[0m
[0;36m[2025-08-21 22:05:22] [INFO] ⏳ Still waiting for ollama... (50s/300s)[0m
[0;35m
╔══════════════════════════════════════════════════════════════╗
║                    CanvasBot Orchestrator                    ║
║              Robust Startup & Recovery System               ║
╚══════════════════════════════════════════════════════════════╝
[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🚀 Starting CanvasBot system with robust orchestration...[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🔍 Starting comprehensive environment validation...[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Canvas credentials found[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Docker is available and running[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Docker Compose available[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🎮 Checking GPU availability...[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Found 3 GPU(s) available[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🔗 Multi-GPU detected, checking NCCL compatibility...[0m
[1;33m[2025-08-21 22:14:01] [WARN] ⚠️ Multi-GPU vLLM configured - will attempt with fallback to single GPU[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🔌 Checking port availability...[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ All required ports are available[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🤖 Validating model configuration...[0m
[0;36m[2025-08-21 22:14:01] [INFO] 📋 vLLM Model: Qwen/Qwen2.5-32B-Instruct-AWQ[0m
[0;36m[2025-08-21 22:14:01] [INFO] 📋 Embedding Model: nomic-embed-text[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Model configuration validated[0m
[0;32m[2025-08-21 22:14:01] [SUCCESS] ✅ Environment validation passed[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🎼 Starting service orchestration...[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🚀 Processing service: ollama[0m
[0;36m[2025-08-21 22:14:01] [INFO] 📊 ollama current state: MISSING[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🆕 ollama container missing, creating new[0m
[0;36m[2025-08-21 22:14:01] [INFO] 🆕 Creating new ollama container...[0m
[0;32m[2025-08-21 22:14:02] [SUCCESS] ✅ Successfully created ollama container[0m
[0;36m[2025-08-21 22:14:02] [INFO] ⏳ Waiting for ollama to be ready...[0m
[0;32m[2025-08-21 22:14:02] [SUCCESS] ✅ ollama is ready[0m
[0;36m[2025-08-21 22:14:02] [INFO] 🚀 Processing service: vllm[0m
[0;36m[2025-08-21 22:14:02] [INFO] 📊 vllm current state: MISSING[0m
[0;36m[2025-08-21 22:14:02] [INFO] 🆕 vllm container missing, creating new[0m
[0;36m[2025-08-21 22:14:02] [INFO] 🆕 Creating new vllm container...[0m
[0;32m[2025-08-21 22:14:03] [SUCCESS] ✅ Successfully created vllm container[0m
[0;36m[2025-08-21 22:14:03] [INFO] ⏳ Waiting for vllm to be ready...[0m
[0;32m[2025-08-21 22:14:03] [SUCCESS] ✅ vllm is ready[0m
[0;36m[2025-08-21 22:14:03] [INFO] 🚀 Processing service: canvasbot[0m
[0;36m[2025-08-21 22:14:03] [INFO] 📊 canvasbot current state: MISSING[0m
[0;36m[2025-08-21 22:14:03] [INFO] 🆕 canvasbot container missing, creating new[0m
[0;36m[2025-08-21 22:14:03] [INFO] 🆕 Creating new canvasbot container...[0m
[0;32m[2025-08-21 22:14:03] [SUCCESS] ✅ Successfully created canvasbot container[0m
[0;36m[2025-08-21 22:14:03] [INFO] ⏳ Waiting for canvasbot to be ready...[0m
[0;36m[2025-08-21 22:14:14] [INFO] ⏳ Still waiting for canvasbot... (10s/300s)[0m
[0;32m[2025-08-21 22:14:14] [SUCCESS] ✅ canvasbot is ready[0m
[0;36m[2025-08-21 22:14:14] [INFO] 🚀 Processing service: open-webui[0m
[0;36m[2025-08-21 22:14:14] [INFO] 📊 open-webui current state: MISSING[0m
[0;36m[2025-08-21 22:14:14] [INFO] 🆕 open-webui container missing, creating new[0m
[0;36m[2025-08-21 22:14:14] [INFO] 🆕 Creating new open-webui container...[0m
[0;32m[2025-08-21 22:14:14] [SUCCESS] ✅ Successfully created open-webui container[0m
[0;32m[2025-08-21 22:14:14] [SUCCESS] ✅ Service orchestration completed[0m
[0;36m[2025-08-21 22:14:14] [INFO] 📊 Generating system status report...[0m

[0;34m╔══════════════════════════════════════════════╗[0m
[0;34m║                System Status                 ║[0m
[0;34m╚══════════════════════════════════════════════╝[0m

[0;36mOperation Mode:[0m FULL
[0;36mOrchestrator State:[0m STARTING
[0;36mRuntime:[0m 13 seconds

[1;33mService Status:[0m
  ✅ ollama: CREATED (HEALTHY)
  ✅ vllm: CREATED (UNHEALTHY)
  ✅ canvasbot: CREATED (HEALTHY)
  ❌ open-webui: CREATED (UNHEALTHY)

[1;33mService URLs:[0m
  🤖 CanvasBot API: http://localhost:3001
  🌐 Open WebUI: http://localhost:8081
  ⚡ vLLM API: http://localhost:8000
  🧠 Ollama API: http://localhost:11435

[0;32m✅ No critical issues detected[0m
[0;32m[2025-08-21 22:14:14] [SUCCESS] 🎉 CanvasBot system startup completed successfully![0m
[0;36m[2025-08-22 07:58:52] [INFO] 🛑 Stopping CanvasBot system...[0m
[0;36m[2025-08-22 07:58:52] [INFO] 🛑 Initiating graceful shutdown...[0m
[0;36m[2025-08-22 07:58:52] [INFO] 🧹 Cleaning up orchestrator state...[0m
[0;32m[2025-08-22 07:58:52] [SUCCESS] ✅ Graceful shutdown completed[0m
[0;35m
╔══════════════════════════════════════════════════════════════╗
║                    CanvasBot Orchestrator                    ║
║              Robust Startup & Recovery System               ║
╚══════════════════════════════════════════════════════════════╝
[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🚀 Starting CanvasBot system with robust orchestration...[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🔍 Starting comprehensive environment validation...[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Canvas credentials found[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Docker is available and running[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Docker Compose available[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🎮 Checking GPU availability...[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Found 3 GPU(s) available[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🔗 Multi-GPU detected, checking NCCL compatibility...[0m
[1;33m[2025-08-22 19:11:46] [WARN] ⚠️ Multi-GPU vLLM configured - will attempt with fallback to single GPU[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🔌 Checking port availability...[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ All required ports are available[0m
[0;36m[2025-08-22 19:11:46] [INFO] 🤖 Validating model configuration...[0m
[0;36m[2025-08-22 19:11:46] [INFO] 📋 vLLM Model: Qwen/Qwen2.5-32B-Instruct-AWQ[0m
[0;36m[2025-08-22 19:11:46] [INFO] 📋 Embedding Model: nomic-embed-text[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Model configuration validated[0m
[0;32m[2025-08-22 19:11:46] [SUCCESS] ✅ Environment validation passed[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🎼 Starting service orchestration...[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🚀 Processing service: ollama[0m
[0;36m[2025-08-22 19:11:47] [INFO] 📊 ollama current state: MISSING[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🆕 ollama container missing, creating new[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🆕 Creating new ollama container...[0m
[0;32m[2025-08-22 19:11:47] [SUCCESS] ✅ Successfully created ollama container[0m
[0;36m[2025-08-22 19:11:47] [INFO] ⏳ Waiting for ollama to be ready...[0m
[0;32m[2025-08-22 19:11:47] [SUCCESS] ✅ ollama is ready[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🚀 Processing service: vllm[0m
[0;36m[2025-08-22 19:11:47] [INFO] 📊 vllm current state: MISSING[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🆕 vllm container missing, creating new[0m
[0;36m[2025-08-22 19:11:47] [INFO] 🆕 Creating new vllm container...[0m
[0;32m[2025-08-22 19:11:48] [SUCCESS] ✅ Successfully created vllm container[0m
[0;36m[2025-08-22 19:11:48] [INFO] ⏳ Waiting for vllm to be ready...[0m
[0;32m[2025-08-22 19:11:48] [SUCCESS] ✅ vllm is ready[0m
[0;36m[2025-08-22 19:11:48] [INFO] 🚀 Processing service: canvasbot[0m
[0;36m[2025-08-22 19:11:48] [INFO] 📊 canvasbot current state: MISSING[0m
[0;36m[2025-08-22 19:11:48] [INFO] 🆕 canvasbot container missing, creating new[0m
[0;36m[2025-08-22 19:11:48] [INFO] 🆕 Creating new canvasbot container...[0m
[0;32m[2025-08-22 19:11:49] [SUCCESS] ✅ Successfully created canvasbot container[0m
[0;36m[2025-08-22 19:11:49] [INFO] ⏳ Waiting for canvasbot to be ready...[0m
[0;36m[2025-08-22 19:11:59] [INFO] ⏳ Still waiting for canvasbot... (10s/300s)[0m
[0;32m[2025-08-22 19:11:59] [SUCCESS] ✅ canvasbot is ready[0m
[0;36m[2025-08-22 19:11:59] [INFO] 🚀 Processing service: open-webui[0m
[0;36m[2025-08-22 19:11:59] [INFO] 📊 open-webui current state: MISSING[0m
[0;36m[2025-08-22 19:11:59] [INFO] 🆕 open-webui container missing, creating new[0m
[0;36m[2025-08-22 19:11:59] [INFO] 🆕 Creating new open-webui container...[0m
[0;32m[2025-08-22 19:11:59] [SUCCESS] ✅ Successfully created open-webui container[0m
[0;32m[2025-08-22 19:11:59] [SUCCESS] ✅ Service orchestration completed[0m
[0;36m[2025-08-22 19:11:59] [INFO] 📊 Generating system status report...[0m

[0;34m╔══════════════════════════════════════════════╗[0m
[0;34m║                System Status                 ║[0m
[0;34m╚══════════════════════════════════════════════╝[0m

[0;36mOperation Mode:[0m FULL
[0;36mOrchestrator State:[0m STARTING
[0;36mRuntime:[0m 13 seconds

[1;33mService Status:[0m
  ✅ ollama: CREATED (HEALTHY)
  ✅ vllm: CREATED (UNHEALTHY)
  ✅ canvasbot: CREATED (HEALTHY)
  ❌ open-webui: CREATED (UNHEALTHY)

[1;33mService URLs:[0m
  🤖 CanvasBot API: http://localhost:3001
  🌐 Open WebUI: http://localhost:8081
  ⚡ vLLM API: http://localhost:8000
  🧠 Ollama API: http://localhost:11435

[0;32m✅ No critical issues detected[0m
[0;32m[2025-08-22 19:11:59] [SUCCESS] 🎉 CanvasBot system startup completed successfully![0m
[0;36m[2025-08-22 19:13:56] [INFO] 📊 Checking system status...[0m
[0;36m[2025-08-22 19:13:56] [INFO] 📊 Generating system status report...[0m

[0;34m╔══════════════════════════════════════════════╗[0m
[0;34m║                System Status                 ║[0m
[0;34m╚══════════════════════════════════════════════╝[0m

[0;36mOperation Mode:[0m FULL
[0;36mOrchestrator State:[0m INITIALIZING
[0;36mRuntime:[0m 0 seconds

[1;33mService Status:[0m

[1;33mService URLs:[0m
  🤖 CanvasBot API: http://localhost:3001
  🌐 Open WebUI: http://localhost:8081
  ⚡ vLLM API: http://localhost:8000
  🧠 Ollama API: http://localhost:11435

[0;31m⚠️ Critical Issues Detected:[0m
  ❌ Canvas access token not configured

[1;33m💡 Troubleshooting Steps:[0m
  1. Check logs: [0;36mtail -f /home/bencan/projects/canvasCheckerBot/logs/orchestrator.log[0m
  2. Restart services: [0;36m./scripts/orchestrator.sh restart[0m
  3. Check configuration: [0;36m./scripts/orchestrator.sh validate[0m
