version: '3.8'

services:
  canvasbot:
    build: .
    container_name: canvasbot-api
    ports:
      - "0.0.0.0:3001:3001"  # Network accessible by default
    environment:
      - NODE_ENV=production
      - PORT=3001
      - CANVAS_BASE_URL=${CANVAS_BASE_URL}
      - CANVAS_ACCESS_TOKEN=${CANVAS_ACCESS_TOKEN}
      - STUDENT_ID=${STUDENT_ID}
      - VLLM_BASE_URL=http://vllm:8000
      - VLLM_MODEL=${VLLM_MODEL:-Qwen/Qwen2.5-32B-Instruct-AWQ}
      - OLLAMA_BASE_URL=http://ollama:11434
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-nomic-embed-text}
    volumes:
      - ./cache:/app/cache
      - ./logs:/app/logs
      - ./.env:/app/.env:ro
    restart: unless-stopped
    depends_on:
      - vllm
      - ollama
    networks:
      - canvasbot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # vLLM High-Performance Inference Engine
  vllm:
    image: vllm/vllm-openai:latest
    container_name: canvasbot-vllm
    ports:
      - "0.0.0.0:8000:8000"
    command: ["--model", "${VLLM_MODEL:-Qwen/Qwen2.5-32B-Instruct-AWQ}", "--trust-remote-code", "--tensor-parallel-size", "${VLLM_GPU_COUNT:-1}", "--max-model-len", "${VLLM_MAX_LENGTH:-10176}"]
    environment:
      - MODEL_NAME=${VLLM_MODEL:-Qwen/Qwen2.5-32B-Instruct-AWQ}
      - TENSOR_PARALLEL_SIZE=${VLLM_GPU_COUNT:-1}
      - MAX_MODEL_LEN=${VLLM_MAX_LENGTH:-10176}
      - TRUST_REMOTE_CODE=true
    volumes:
      - vllm_cache:/root/.cache
      - ./models:/models
    restart: unless-stopped
    networks:
      - canvasbot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3
    # Requires GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

  # Ollama for Embeddings Only
  ollama:
    image: ollama/ollama:latest
    container_name: canvasbot-embeddings
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - canvasbot-network
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['2']
              capabilities: [gpu]

  # CanvasBot Chat Interface (Oobabooga)
  oobabooga:
    image: atinoda/text-generation-webui:latest
    container_name: canvasbot-chat
    ports:
      - "0.0.0.0:7860:7860"  # Network accessible by default
    volumes:
      - ./models:/app/models
      - ./characters:/app/characters
      - ./presets:/app/presets
      - ./oobabooga-config:/app/settings:rw
    environment:
      - EXTRA_LAUNCH_ARGS=--api --extensions openai --listen --listen-host 0.0.0.0 --listen-port 7860
      - OPENAI_API_BASE=http://canvasbot:3001/v1
      - OPENAI_API_KEY=canvasbot-key
    restart: unless-stopped
    depends_on:
      - canvasbot
      - vllm
    networks:
      - canvasbot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - chat

  # Alternative: Open WebUI Interface
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: canvasbot-webui
    ports:
      - "0.0.0.0:8081:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENAI_API_BASE_URL=http://canvasbot:3001/v1
      - OPENAI_API_KEY=canvasbot-key
      # Authentication Configuration
      - WEBUI_AUTH=${WEBUI_AUTH:-true}
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-canvasbot-secret-key}
      # Development Settings
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE:-user}
    volumes:
      - open_webui_data:/app/backend/data
    restart: unless-stopped
    depends_on:
      - vllm
      - ollama
      - canvasbot
    networks:
      - canvasbot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - webui

volumes:
  ollama_data:
  open_webui_data:
  vllm_cache:

networks:
  canvasbot-network:
    name: canvasbot
    driver: bridge